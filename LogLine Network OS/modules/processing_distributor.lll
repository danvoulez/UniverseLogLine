module processing_distributor
version: "2.0.0"
use core_schema as core
use resource_allocator as ra
use memory_coordinator as mem
use gpu_scheduler as gpu
use timeline_logger as tl

entity CpuSpan
  key: span_id (uuid)
  properties:
    - tenant_id: string
    - span_id: uuid
    - node_id: string
    - contract_id: uuid
    - task_description: string
    - cpu_seconds_reserved: float
    - memory_required_mb: int
    - gpu_slices: list[json] = []
    - started_at: core.datetime?
    - finished_at: core.datetime?
    - status: string = "queued"

flow dispatch_task
  inputs: tenant_id, contract (core.Contract)
  outputs: CpuSpan
  steps:
    - let node = ra.pick_node_for_contract(tenant_id, contract)
    - let ram = mem.allocate_ram(tenant_id, node.node_id, contract.requirements.ram_gb*1024, contract.contract_id)
    - let gpus = []
    - if contract.requirements.gpu.count:
        set gpus = gpu.allocate_gpu(tenant_id, node.node_id, contract.requirements.gpu.count, contract.requirements.gpu.mig_profile)
    - let rsrv = ra.reserve_resources(tenant_id, node.node_id, contract.requirements, "45s")
    - create CpuSpan { tenant_id, span_id: uuid(), node_id: node.node_id, contract_id: contract.contract_id, task_description: contract.workflow, cpu_seconds_reserved: contract.requirements.cpu_cores * 60, memory_required_mb: contract.requirements.ram_gb*1024, gpu_slices: gpus, started_at: now(), status: "running" }
    - tl.log_span(tenant_id, contract.contract_id, node.node_id, "running", {ram, rsrv, gpus})
    - return self

flow finish_task
  inputs: tenant_id, span_id, ok, output_cid?
  steps:
    - let s = select CpuSpan where span_id=span_id
    - set s.finished_at = now(); set s.status = (ok ? "succeeded" : "failed")
    - tl.log_span(tenant_id, s.contract_id, s.node_id, s.status, {output_cid})
    - mem.release_ram(tenant_id, s.node_id, chunk_id_of(s), s.memory_required_mb, s.contract_id)
